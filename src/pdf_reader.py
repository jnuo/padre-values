
import os
import base64
import json
import time
import fitz  # pymupdf
from openai import OpenAI
from src.config import OPENAI_API_KEY

PROMPT = (
    "AÅŸaÄŸÄ±daki laboratuvar sayfasÄ±ndan TÃœM gÃ¼ncel 'SonuÃ§' deÄŸerlerini Ã§Ä±kar.\n"
    "Kurallar:\n"
    "- Parantezli eski sonuÃ§larÄ± alma.\n"
    "- 10,7 â†’ 10.7 nokta yap.\n"
    "- H/L bayraÄŸÄ±nÄ± 'flag' alanÄ±na yaz.\n"
    "- % ve # ayrÄ± anahtar (Ã¶rn: NÃ¶trofil% / NÃ¶trofil#).\n"
    "- 'Numune AlÄ±m Tarihi'ni tespit et ve sadece tarihi ISO 'YYYY-MM-DD' formatÄ±nda ver (saatleri atla).\n"
    "- Her test iÃ§in mÃ¼mkÃ¼nse referans aralÄ±ÄŸÄ±nÄ± Ã§Ä±kar: alt sÄ±nÄ±r ve Ã¼st sÄ±nÄ±r.\n"
    "- Referans aralÄ±ÄŸÄ± mevcutsa 'ref_low' ve 'ref_high' alanlarÄ±nÄ± doldur. Yoksa boÅŸ bÄ±rak.\n"
    "- Ã‡IKTI: sadece JSON -> {\"sample_date\": \"<YYYY-MM-DD|null>\", \"tests\": { \"<Ad>\": { \"value\": <number>, \"unit\": \"<unit|null>\", \"flag\": \"<H|L|N|null>\", \"ref_low\": <number|null>, \"ref_high\": <number|null> } } }}"
)

def extract_labs_from_pdf(pdf_path: str, dpi: int = 220) -> dict:
    """
    Extracts lab values from a PDF file using OpenAI GPT (image-based extraction).
    Caches the result as a .labs.json file next to the PDF for future runs.
    Only calls OpenAI if the cache does not exist.
    Args:
        pdf_path: Path to the PDF file.
        dpi: Resolution for page image conversion (default 220).
    Returns:
        Dictionary with 'sample_date' and 'tests' keys.
    """
    file_name = os.path.basename(pdf_path)
    cache_path = pdf_path + ".labs.json"

    # Check cache first
    if os.path.exists(cache_path):
        print(f"  ðŸ“‹ Cache hit: {file_name}")
        with open(cache_path, "r", encoding="utf-8") as f:
            cached = json.load(f)
            print(f"     â†’ {len(cached.get('tests', {}))} tests, date: {cached.get('sample_date')}")
            return cached

    print(f"  ðŸ¤– Calling OpenAI API for: {file_name}")
    start_time = time.time()

    client = OpenAI(api_key=OPENAI_API_KEY)

    def page_to_b64(page, dpi=220):
        """Convert a PDF page to a base64 PNG image string."""
        pix = page.get_pixmap(dpi=dpi, alpha=False)
        return "data:image/png;base64," + base64.b64encode(pix.tobytes("png")).decode()

    out = {"sample_date": None, "tests": {}}
    with fitz.open(pdf_path) as doc:
        num_pages = len(doc)
        print(f"     â†’ Processing {num_pages} page(s)...")

        for page_num, page in enumerate(doc, 1):
            page_start = time.time()
            resp = client.chat.completions.create(
                model="gpt-5-mini",
                temperature=0,
                response_format={"type": "json_object"},
                max_tokens=4000,
                messages=[{
                    "role": "user",
                    "content": [
                        {"type": "text", "text": PROMPT},
                        {"type": "image_url", "image_url": {"url": page_to_b64(page, dpi=dpi)}},
                    ],
                }],
            )
            page_time = time.time() - page_start
            data = json.loads(resp.choices[0].message.content)
            tests_found = len(data.get("tests", {}))
            print(f"     â†’ Page {page_num}/{num_pages}: {tests_found} tests ({page_time:.1f}s)")

            # Merge tests from each page
            out["tests"].update(data.get("tests", {}))
            # Keep the first non-empty sample_date
            if not out["sample_date"]:
                out["sample_date"] = data.get("sample_date")

    total_time = time.time() - start_time
    print(f"  âœ… Extracted {len(out['tests'])} tests, date: {out['sample_date']} ({total_time:.1f}s total)")

    # Save result for future reuse
    with open(cache_path, "w", encoding="utf-8") as f:
        json.dump(out, f, ensure_ascii=False, indent=2)
    print(f"  ðŸ’¾ Cached to: {os.path.basename(cache_path)}")

    return out
